{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Graph Exploration - Skill Gap Analysis\n",
        "\n",
        "This notebook explores graph-based analysis of job skills and relationships.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "from core.graph_analysis import (\n",
        "    build_skill_cooccurrence_graph,\n",
        "    compute_centralities,\n",
        "    detect_communities,\n",
        "    get_skill_importance_scores,\n",
        "    find_bridge_skills\n",
        ")\n",
        "from core.analysis import cluster_jobs, interpret_clusters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Sample Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load processed jobs data\n",
        "# Replace with your actual data file\n",
        "try:\n",
        "    df = pd.read_csv('../data/processed_jobs_data_analyst_madrid.csv')\n",
        "    # Convert skills_detected from string to list if needed\n",
        "    if 'skills_detected' in df.columns:\n",
        "        import ast\n",
        "        df['skills_detected'] = df['skills_detected'].apply(\n",
        "            lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
        "        )\n",
        "    print(f\"Loaded {len(df)} jobs\")\n",
        "except FileNotFoundError:\n",
        "    print(\"No processed data found. Run the main app first to generate data.\")\n",
        "    df = pd.DataFrame()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build Skill Co-occurrence Graph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(df) > 0:\n",
        "    G = build_skill_cooccurrence_graph(df)\n",
        "    \n",
        "    print(f\"Graph nodes (skills): {len(G.nodes())}\")\n",
        "    print(f\"Graph edges (co-occurrences): {len(G.edges())}\")\n",
        "    print(f\"Graph density: {nx.density(G):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute Centralities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(df) > 0 and len(G.nodes()) > 0:\n",
        "    centrality_df = compute_centralities(G)\n",
        "    print(\"Top 10 Skills by Degree Centrality:\")\n",
        "    print(centrality_df.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Community Detection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(df) > 0 and len(G.nodes()) > 0:\n",
        "    communities = detect_communities(G)\n",
        "    \n",
        "    # Count skills per community\n",
        "    comm_counts = Counter(communities.values())\n",
        "    print(f\"Found {len(comm_counts)} communities\")\n",
        "    print(f\"Community sizes: {dict(comm_counts)}\")\n",
        "    \n",
        "    # Show skills in each community\n",
        "    for comm_id in sorted(comm_counts.keys()):\n",
        "        skills_in_comm = [skill for skill, cid in communities.items() if cid == comm_id]\n",
        "        print(f\"\\nCommunity {comm_id} ({len(skills_in_comm)} skills):\")\n",
        "        print(f\"  {', '.join(skills_in_comm[:10])}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
